# MatrixLib Performance Benchmarks

This directory contains performance benchmarks for MatrixLib using [Google Benchmark](https://github.com/google/benchmark).

## Building Benchmarks

### Prerequisites

Install Google Benchmark:

**Ubuntu/Debian:**
```bash
sudo apt install libbenchmark-dev
```

**macOS:**
```bash
brew install google-benchmark
```

**Windows (vcpkg):**
```bash
vcpkg install benchmark
```

**From source:**
```bash
git clone https://github.com/google/benchmark.git
cd benchmark
cmake -E make_directory "build"
cmake -E chdir "build" cmake -DBENCHMARK_DOWNLOAD_DEPENDENCIES=on -DCMAKE_BUILD_TYPE=Release ../
cmake --build "build" --config Release
cmake --build "build" --config Release --target install
```

### Build Commands

```bash
cd matrixlib
mkdir build && cd build
cmake .. -DMATRIX_LINEAR_BUILD_BENCHMARKS=ON
cmake --build .
```

## Running Benchmarks

```bash
# Run all benchmarks
./benchmarks/bench_matrix_multiply
./benchmarks/bench_simd
./benchmarks/bench_constexpr
./benchmarks/bench_vector_ops

# Run with specific filters
./benchmarks/bench_matrix_multiply --benchmark_filter=BM_Matrix4x4.*

# Run with custom time unit
./benchmarks/bench_vector_ops --benchmark_time_unit=us

# Run with JSON output
./benchmarks/bench_simd --benchmark_format=json --benchmark_out=results.json
```

## Benchmark Categories

### 1. Matrix Multiplication (`bench_matrix_multiply.cpp`)
- 3x3 and 4x4 matrix multiplication
- Chain multiplications
- Matrix-vector products
- Transpose operations
- Determinant and inverse calculations

### 2. SIMD Operations (`bench_simd.cpp`)
- Vec3 operations (dot, cross, normalize)
- Vec4 operations (SIMD-optimized)
- Quaternion operations
- Array operations (memory bandwidth)

### 3. Constexpr vs Runtime (`bench_constexpr.cpp`)
- Compile-time vs runtime initialization
- Identity matrix creation
- Zero vector creation
- Special angle rotations
- Lookup table performance

### 4. Vector Operations (`bench_vector_ops.cpp`)
- Length calculations
- Distance computations
- Interpolation (lerp)
- Reflection and projection
- Swizzle operations
- Batch normalization

## Interpreting Results

Benchmark output shows:
- **Time**: Average time per operation (ns, Î¼s, ms)
- **CPU**: CPU time (may differ from wall time)
- **Iterations**: Number of times the benchmark ran

Lower times are better. Compare SIMD vs non-SIMD builds to see optimization benefits.

## Optimization Tips

1. **Enable compiler optimizations:**
   ```bash
   cmake .. -DCMAKE_BUILD_TYPE=Release -DMATRIX_LINEAR_BUILD_BENCHMARKS=ON
   ```

2. **Enable SIMD:**
   ```bash
   cmake .. -DMATRIXLIB_ENABLE_NEON=ON  # For ARM
   cmake .. -DMATRIXLIB_ENABLE_CMSIS=ON # For Cortex-M
   ```

3. **Try different C++ standards:**
   ```bash
   cmake .. -DCMAKE_CXX_STANDARD=20  # Test C++20 optimizations
   ```

4. **Profile with perf (Linux):**
   ```bash
   perf record --call-graph dwarf ./bench_matrix_multiply
   perf report
   ```

## Expected Performance

On typical hardware (x86_64, ARM Cortex-A):
- 4x4 matrix multiply: ~50-200 ns
- Vec3 dot product: ~5-20 ns
- Vec3 normalize: ~20-100 ns
- Constexpr initialization: ~1-5 ns (compile-time optimized)

SIMD builds should show 2-4x speedup for float operations.
